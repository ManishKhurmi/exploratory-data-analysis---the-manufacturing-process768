{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Imports \n",
    "import DataFrameInfo_class as info\n",
    "import pandas as pd \n",
    "from scipy.stats import normaltest \n",
    "from statsmodels.graphics.gofplots import qqplot \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "failure_data = pd.read_csv('failure_data_after_data_transformation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotter Class\n",
    "\n",
    "class Plotter: \n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "    \n",
    "    def plot_hist(self, column_name):\n",
    "        self.df[column_name].hist(bins = 40)\n",
    "        plt.show()\n",
    "\n",
    "    def normal_test(self, column_name):\n",
    "        stat, p = normaltest(self.df[column_name], nan_policy = 'omit')\n",
    "        print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    \n",
    "    def plot_qq(self, column_name):\n",
    "        qq_plot_air_temp = qqplot(self.df[column_name], scale=1, line ='q')\n",
    "        plt.show()\n",
    "\n",
    "    def print_mean(self, column_name):\n",
    "        print(f'The mean of {column_name} is {self.df[column_name].mean()}')\n",
    "    \n",
    "    def print_median(self, column_name):\n",
    "        print(f'The median of {column_name} is {self.df[column_name].median()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add analysis from plotter_v2.py\n",
    "# The majority of this is for skewness \n",
    "\n",
    "# brain dump \n",
    "# use the missing data analysis and put it here from the longer script \n",
    "# perform treatement for any skewed data \n",
    "# data transformations\n",
    "# update the DataTransformation Class \n",
    "# data cleaning:\n",
    "    # data info \n",
    "    # MCAR / MAR / NMAR? - I have answered this a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following Data Transformation act as a treatement to missing data in the data set \n",
    "\n",
    "# Treating the NULL values \n",
    "failure_data['Air temperature [K]'] = failure_data['Air temperature [K]'].fillna(failure_data['Air temperature [K]'].median())\n",
    "failure_data['Process temperature [K]'] = failure_data['Process temperature [K]'].fillna(failure_data['Process temperature [K]'].median())\n",
    "failure_data.dropna(subset='Tool wear [min]', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new variable after treating the null variables\n",
    "failure_data_without_null = failure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis & visualisatoin ideas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA ideas \n",
    "\n",
    "# check the balance of the data set for `machine failure` variable.\n",
    "    # do this is with a bar chart \n",
    "# Do a correlation matrix of all numerical variables, where the dependant (y) variable is 'machine failure' \n",
    "\n",
    "# categorical plots \n",
    "# correcting the skew - do this first for the independant variables that have the highest correlation \n",
    "# count plots of our nominal category data (those with binary data)\n",
    "# summary plots - pairplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0    9188\n",
       "1     328\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_data_without_null['Machine failure'].value_counts()\n",
    "# Data set is heavyly in balanced, this will cause a bias in ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # do this is with a bar chart \n",
    "# Do a correlation matrix of all numerical variables, where the dependant (y) variable is 'machine failure' \n",
    "\n",
    "# categorical plots \n",
    "# correcting the skew - do this first for the independant variables that have the highest correlation \n",
    "# count plots of our nominal category data (those with binary data)\n",
    "# summary plots - pairplot \n",
    "\n",
    "# create a bar plot of purpose vs amount\n",
    "sns.barplot(data=failure_data_after_transformations['Machine failure'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
