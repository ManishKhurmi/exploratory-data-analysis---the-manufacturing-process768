Use Classes & Methods to make the EDA process more efficient 
Use .ipynb files for visualisation & analysis 
label variables well to ensure there are not overwriting issues in the code 
create seperate scripts for testing classes when needed, have a main script that shows the whole thought process

Are measures of Skewness useful for Binary Data? Elaborate on your answer.
- Binary data is another form of categorical data, to which measures of skew are not very useful. 
- Instead use measures of frequency. 
- Might be worthwhile looking at logistic regression for modelling the relationship between the binary dependant variable and one or more independant variables.
- Measures of skew are however useful for continous data. 

Learn the theory behind the normality & skewness tests

When applyting data transformation steps e.g. cleaning, correcting for skewness, 
- create a copy of the data frame & rename the variables. This ensures reproducability. As a check, re-run the code block. 
- check for null values as a result of the transformation. 

Why do I need to include 'self' as a parameter for any method I define in a class?
- Method binding. As the init parameter is parsed first by python any subsequent method in the class needs to bind with the __init__ func of said class.
- This binding allows the method to be aware of the instance it is operating on.
- Even if I do not need access to the information in the __init__ func of a class, I still need to define 'self' as a parameter for any method.

lean code with treating for skewness or other statical methods:
- perform the whole end-to-end on one parameter first then create functions for classes, to apply the same methods to other parameters 

############################################################################################################################################
Project decisions
- box plots > scatter plots for looking at outliers 
- Skew tests & Histograms > Normal test & QQ plot
- Skew transformation was done for Air temperature, condenced all the values, loss of interpretation and information, this approach does not add much for the model either. 

Search for `EDA Note` in the script to see where to go back and change decision according to model performance
e.g. ***Strategic EDA decision***: adjust |z| scores.
############################################################################################################################################


if a transformation is made on a column. Rename said column. For example if the skewness transformation on air_temp was kept then rename that column 


Explain what degrees of freedom (df) is, in the context of statistics?
- `df` determines the number of values in a calculaiton that are free to vary. 
- We can think of it as the number of independent pieces of information needed to estimate a statical parameter.
- Chisquared example: (Number of rows - 1) * (Number of columns - 1)
-(2 - 1) * (2 - 1) = 1, Therefore 1 df for out 2 x 2 table, knowing the totals for each row and column, we only need 1 cells value to determine all the other values in our table

Explain the concept of a p-value in statistics?
- The p-value is a number that helps us understand the strength of the evidence against the null hypothesis, which is the assumption that there is no relationship between the variables being studied 
- A low p-value suggestions strong evidence against the null hypothesis.

What is the Null Hypothesis?
- The null hypothesis is a well defined statement to test whether there's evidence for a particular effect or association. 
- (H0): is a statement that there is no affect, no difference, no association between variables. It serves as the starting point for statistical testing.  


#### Notes for the project 
- models that are designed for binary data 
- is normalising the air temperature worth it? - in correcting for the skew, we lose the meaningful information that the variable contains 

#### How can i create tests so that the issue of labelling data, overighting data etc 

How to interpret p-values:
- the 0.05 boundry relates to the tails of a normal distribution. where the y-axis is the probability density function and the x axis is the z-scores. 
- The x-axis (z-scors) represent the effect of the test statistic is relatively large, large enough that we cannot ignore the effect. Therefore it is deemed to be significant.
- Understanding the z-scores is key here, they represent (as you get further away from the mean) a larger and larger effect on the dependant variable. 
- Take the example of testing a new drug. The p-values in the middle or majority of the normal distrubtion represent a mediocure effect of the drug, whereas the tails represent the effect of the test drug being relatively large (95th percentaile), so large that we cannont ignore this new drug.

What is the difference between the Chi-squared test and general tests for collinearity?
- Chi-squared test is designed for 

when testing for collinearity, I'm using 'VIF'. should the 'r**2' term in the VIF calculation come from a model that predicts the dependant variable using all the independant variables or from a model that predicts the dependant variable using only the variable pairs that I think are correlated?
- `R^2` term comes from a model that regresses the variable of interest against ALL other variables of interested. 
why is it a bad idea to use the `R^2` from a model that only regresses the variable of interest on the pairs of variables that might be correlated? 
- Omitted Variable Bias 
- incomplete multicolinearity assessment: multicolinearity can arise from the interactions among multiple variables simultaneously
- Higher-order affects: not just pairs, e.g. a pair that are correlated with a single variable 

############################################################################################################################################
What is a `DataFrameGroupBy` object?
This object is like a dictionary, where the keys are the unique values in column we grouped by. 
- Example using 'Type':
{
    'L': DataFrame containing rows where Type == 'L',
    'M': DataFrame containing rows where Type == 'M',
    'H': DataFrame containing rows where Type == 'H'
}

#Â check if this is what is expected 
# for group_name, grouped_df in group_by_product_type_df:
#     print(f"Group: {group_name}")
#     print(f"Length of df: {len(grouped_df)}")
#     print("\n")
############################################################################################################################################