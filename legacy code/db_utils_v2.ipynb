{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# Step 3: function to parse a yaml file into a dictionary format \n",
    "yaml_file = 'credentials.yaml'\n",
    "\n",
    "def yaml_to_dict(yaml_file):\n",
    "        with open(yaml_file) as file:\n",
    "               return yaml.safe_load(file)\n",
    "\n",
    "# Test with the \"credentials.yaml\" file               \n",
    "credentials_dict = yaml_to_dict(yaml_file='credentials.yaml')\n",
    "credentials_dict       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in credentials_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function \n",
    "def initialise_SQL_engine(dict):\n",
    "    DATABASE_TYPE = dict['DATABASE_TYPE']\n",
    "    DBAPI = dict['DBAPI']\n",
    "    RDS_USER = dict['RDS_USER']\n",
    "    RDS_PASSWORD = dict['RDS_PASSWORD']\n",
    "    RDS_HOST = dict['RDS_HOST']\n",
    "    RDS_PORT = dict['RDS_PORT']\n",
    "    RDS_DATABASE = dict['RDS_DATABASE']\n",
    "\n",
    "    engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{RDS_USER}:{RDS_PASSWORD}@{RDS_HOST}:{RDS_PORT}/{RDS_DATABASE}\")\n",
    "    engine.execution_options(isolation_level='AUTOCOMMIT').connect()\n",
    "\n",
    "    return engine\n",
    "\n",
    "# Step 6 - extract data from RDS and return it as a pandas dataframe \n",
    "def extract_data(dict, table_name):\n",
    "    engine = initialise_SQL_engine(dict)\n",
    "    table = pd.read_sql_table(table_name, engine)\n",
    "    return table\n",
    "\n",
    "def export_table_as_csv(dict, table_name):\n",
    "    table = extract_data(dict, table_name)\n",
    "    table.to_csv(f\"{table_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_SQL_engine(dict= credentials_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(dict= credentials_dict, table_name='failure_data').head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_as_csv(dict=credentials_dict, table_name='failure_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RDS_HOST': 'eda-projects.cq2e8zno855e.eu-west-1.rds.amazonaws.com',\n",
       " 'RDS_PASSWORD': 'EDAprocessanalysis',\n",
       " 'RDS_USER': 'manufacturinganalyst',\n",
       " 'RDS_DATABASE': 'process_data',\n",
       " 'RDS_PORT': 5432,\n",
       " 'DATABASE_TYPE': 'postgresql',\n",
       " 'DBAPI': 'psycopg2'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2\n",
    "# Step 3: function to parse a yaml file into a dictionary format \n",
    "yaml_file = 'credentials.yaml'\n",
    "\n",
    "def yaml_to_dict(yaml_file):\n",
    "        with open(yaml_file) as file:\n",
    "               return yaml.safe_load(file)\n",
    "\n",
    "# Test with the \"credentials.yaml\" file               \n",
    "credentials_dict = yaml_to_dict(yaml_file='credentials.yaml')\n",
    "credentials_dict       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDSDatabaseConnector(dict):\n",
    "        '''\n",
    "        This Class is used to connect to the AWS RDS Database\n",
    "        '''\n",
    "        def __init__(self, dict):\n",
    "              self.dict = dict\n",
    "              \n",
    "      # define a function \n",
    "        def initialise_SQL_engine(self):\n",
    "              DATABASE_TYPE = self.dict['DATABASE_TYPE']\n",
    "              DBAPI = self.dict['DBAPI']\n",
    "              RDS_USER = self.dict['RDS_USER']\n",
    "              RDS_PASSWORD = self.dict['RDS_PASSWORD']\n",
    "              RDS_HOST = self.dict['RDS_HOST']\n",
    "              RDS_PORT = self.dict['RDS_PORT']\n",
    "              RDS_DATABASE = self.dict['RDS_DATABASE']\n",
    "\n",
    "              engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{RDS_USER}:{RDS_PASSWORD}@{RDS_HOST}:{RDS_PORT}/{RDS_DATABASE}\")\n",
    "              engine.execution_options(isolation_level='AUTOCOMMIT').connect()\n",
    "\n",
    "              return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql+psycopg2://manufacturinganalyst:***@eda-projects.cq2e8zno855e.eu-west-1.rds.amazonaws.com:5432/process_data)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the Class \n",
    "database_1 = RDSDatabaseConnector(credentials_dict).initialise_SQL_engine() \n",
    "database_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - extract data from RDS and return it as a pandas dataframe \n",
    "def extract_data_as_pandas_df(table_name, engine):\n",
    "    df = pd.read_sql_table(table_name, engine)\n",
    "    return df\n",
    "\n",
    "def export_data_as_csv(data, file_name):\n",
    "    data.to_csv(f\"{file_name}.csv\")\n",
    "#failure_data.to_csv('failure_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = extract_data_as_pandas_df(table_name='failure_data', engine = database_1).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_as_csv(df_1, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDSDatabaseConnector(dict):\n",
    "        '''\n",
    "        This Class is used to connect to the AWS RDS Database\n",
    "        '''\n",
    "        def __init__(self, dict):\n",
    "              self.dict = dict\n",
    "              \n",
    "      # define a function \n",
    "        def initialise_SQL_engine(self):\n",
    "              DATABASE_TYPE = self.dict['DATABASE_TYPE']\n",
    "              DBAPI = self.dict['DBAPI']\n",
    "              RDS_USER = self.dict['RDS_USER']\n",
    "              RDS_PASSWORD = self.dict['RDS_PASSWORD']\n",
    "              RDS_HOST = self.dict['RDS_HOST']\n",
    "              RDS_PORT = self.dict['RDS_PORT']\n",
    "              RDS_DATABASE = self.dict['RDS_DATABASE']\n",
    "\n",
    "              engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{RDS_USER}:{RDS_PASSWORD}@{RDS_HOST}:{RDS_PORT}/{RDS_DATABASE}\")\n",
    "              engine.execution_options(isolation_level='AUTOCOMMIT').connect()\n",
    "\n",
    "              return engine\n",
    "\n",
    "      # Step 6 - extract data from RDS and return it as a pandas dataframe \n",
    "        def extract_data(self, table_name):\n",
    "              engine = initialise_SQL_engine(self.dict)\n",
    "              table = pd.read_sql_table(table_name, engine)\n",
    "              return table\n",
    "\n",
    "        def export_table_as_csv(self, table_name):\n",
    "              table = extract_data(self.dict, table_name)\n",
    "              table.to_csv(f\"{table_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Class \n",
    "database_1 = RDSDatabaseConnector(credentials_dict)\n",
    "database_1.initialise_SQL_engine() \n",
    "database_1.extract_data(table_name='failure_data').head(1) \n",
    "#database_1.export_table_as_csv(table_name='failure_data') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to connect to the RDS Database \n",
    "class RDSDatabaseConnector(dict):\n",
    "        '''\n",
    "        This Class is used to connect to the AWS RDS Database\n",
    "        '''\n",
    "        def __init__(self, dict):\n",
    "              self.dict = dict\n",
    "               \n",
    "        def initialise_SQL_engine(self):\n",
    "              DATABASE_TYPE = self.dict['DATABASE_TYPE']\n",
    "              DBAPI = self.dict['DBAPI']\n",
    "              RDS_USER = self.dict['RDS_USER']\n",
    "              RDS_PASSWORD = self.dict['RDS_PASSWORD']\n",
    "              RDS_HOST = self.dict['RDS_HOST']\n",
    "              RDS_PORT = self.dict['RDS_PORT']\n",
    "              RDS_DATABASE = self.dict['RDS_DATABASE']\n",
    "              \n",
    "              engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{RDS_USER}:{RDS_PASSWORD}@{RDS_HOST}:{RDS_PORT}/{RDS_DATABASE}\")\n",
    "              engine.execution_options(isolation_level='AUTOCOMMIT').connect()\n",
    "              return engine\n",
    "\n",
    "      # Step 6 - extract data from RDS and return it as a pandas dataframe \n",
    "        def extract_data(self, table_name, engine):\n",
    "              table = pd.read_sql_table(table_name, engine)\n",
    "              return table\n",
    "\n",
    "        def export_table_as_csv(self, table_name, engine):\n",
    "              table = extract_data(table_name, engine)\n",
    "              table.to_csv(f\"{table_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Class \n",
    "database_1 = RDSDatabaseConnector(credentials_dict)\n",
    "database_1.initialise_SQL_engine() \n",
    "database_1.extract_data(table_name='failure_data', engine= engine).head(1) \n",
    "database_1.export_table_as_csv(table_name='failure_data', engine= engine) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5  \n",
    "    # Define a method in your RDSDatabaseConnector class which initialises a SQLAlchemy engine from the credentials provided to your class. \n",
    "    # This engine object together with the Pandas library will allow you to extract data from the database.\n",
    "\n",
    "RDS_HOST = 'eda-projects.cq2e8zno855e.eu-west-1.rds.amazonaws.com'\n",
    "RDS_PASSWORD = 'EDAprocessanalysis'\n",
    "RDS_USER = 'manufacturinganalyst'\n",
    "RDS_DATABASE = 'process_data'\n",
    "RDS_PORT = '5432'\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DBAPI = 'psycopg2'\n",
    "\n",
    "engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{RDS_USER}:{RDS_PASSWORD}@{RDS_HOST}:{RDS_PORT}/{RDS_DATABASE}\")\n",
    "\n",
    "DATABASE_TYPE = credentials_dict['DATABASE_TYPE']\n",
    "DBAPI = credentials_dict['DBAPI']\n",
    "RDS_PASSWORD = credentials_dict['RDS_PASSWORD']\n",
    "RDS_HOST = credentials_dict['RDS_HOST']\n",
    "RDS_PORT = credentials_dict['RDS_PORT']\n",
    "RDS_DATABASE = credentials_dict['RDS_DATABASE']\n",
    "\n",
    "\n",
    "engine.execution_options(isolation_level='AUTOCOMMIT').connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
